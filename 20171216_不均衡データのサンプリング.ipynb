{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imbalanced-learnで不均衡データのサンプリングを行う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. データが不均衡な場合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "クラス分類、例えば0：負例と1：正例の二値分類を行う際に、データが不均衡である場合がたびたびあります。\n",
    "\n",
    "例えば、クレジットカードの取引データで、一つの取引に対して<br>\n",
    "  不正利用かどうか（不正利用なら1、それ以外は0）<br>\n",
    "といった値が付与されているカラムがあるとします。\n",
    "\n",
    "通常、不正利用というのは稀に起こる事象なので、不正利用かどうかが格納されているカラムに関しては<br>\n",
    "ほとんどが0で、1がほとんどない、という状況になりがちです。\n",
    "\n",
    "上記の状況で不正利用を予測するようなモデル構築をする場合、目的変数として<br>\n",
    "  不正利用かどうか<br>\n",
    "を用いることになりますが、0と1の比率が50%から極度に乖離します（1の比率が0.X%とかになる）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 予測モデルの問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "こういったデータで予測モデルを構築すると、往々にして負例だけを予測する（予測値がすべて0になる）モデル<br>\n",
    "になりがちです。\n",
    "\n",
    "というのは、不均衡なデータの場合はそれでも<b>「正解率（Accuracy）」が高くなってしまうから</b>です。\n",
    "\n",
    "例えば、目的変数の内訳が、0が99990件、1が10件の場合に、<br>\n",
    "すべて0と出力するモデルができたとすると、<br>\n",
    "正解率は99990 / (99990 + 10) = 99.99%<br>\n",
    "となります。\n",
    "\n",
    "このモデルは正解率は高いのですが、<br>\n",
    "すべての不正利用を見逃す（偽陰性：本当は不正利用（=1）だけれども<br>\n",
    "不正利用でない（=0）と誤って予測する）ことになり、<br>\n",
    "不正利用を検知したいという目的には全くそぐわないモデルになっています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. サンプリングの対策"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不正利用を予測したい、つまり誤検出が多少増えてもから不正利用を検出したいという状況では、<br>\n",
    "サンプリングによって正例と負例の割合を変える、<br>\n",
    "といった方法が採られます。\n",
    "\n",
    "つまり、学習に使われる正例の割合を増やすことで偽陰性を減らし、<br>\n",
    "多少の偽陽性（本当は不正利用していない（=0）けれども不正利用（=1）と誤って予測する）は<br>\n",
    "出しつつも不正利用も検出できるようにします。\n",
    "\n",
    "割合を変化させるにあたって、大きく以下の3パターンがあります。\n",
    "<b>\n",
    "<ol>\n",
    "  <li>Under Sampling：負例を減らす</li>\n",
    "  <li>Over Sampling：正例を増やす</li>\n",
    "  <li>上記の両方を行う</li>\n",
    "</ol>\n",
    "</b>\n",
    "    \n",
    "これら割合の変化は、Pythonではimbalanced-learnというライブラリを用いると簡単に行えます。\n",
    "\n",
    "今回は、このimbalanced-learnを用いてUnder/Over Samplingをどう行うかを簡単に紹介します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ライブラリのインストール"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "インストール方法は以下の二つ。\n",
    "\n",
    "1) pipが利用できる場合は、簡単インストールを行う。\n",
    "<pre>\n",
    "$ pip install -U imbalanced-learn \n",
    "</pre>\n",
    "\n",
    "2) 開発版を使用したい場合は、githubからインストール。\n",
    "<pre>\n",
    "$ git clone https://github.com/scikit-learn-contrib/imbalanced-learn.git\n",
    "$ cd imbalanced-learn\n",
    "$ python setup.py install\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. サンプルデータ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不均衡データを人工的に生成します。<br>\n",
    "こういった人工データは、sklearn.datasets.make_classificationを用いると<br>\n",
    "簡単に作成できます。\n",
    "\n",
    "今回、10万件のデータで、正例が10件のデータを以下のようにして作成しました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "df = make_classification(\n",
    "    n_samples = 100000, # sample size\n",
    "    n_features = 10,          # 特徴量の数\n",
    "    n_informative = 2,       # 目的変数のラベルと相関が強い特徴量(Informative fearture）の数\n",
    "    n_redundant = 0,         # Informative featureの線形結合から作られる特徴量(Redundant fearture）の数\n",
    "    n_repeated = 0,           # Infomative、Redundant featureのコピーからなる特徴量の数(Repeated feature)\n",
    "    n_classes = 2,                           # 分類するクラス数\n",
    "    n_clusters_per_class = 2,       # 1クラスあたりのクラスタ数\n",
    "    weights = [0.9999, 0.0001],  #  クラスの比率\n",
    "    flip_y = 0,\n",
    "    class_sep = 1.0,\n",
    "    hypercube = True,\n",
    "    shift = 0.0, \n",
    "    scale = 1.0,\n",
    "    shuffle = True,\n",
    "    random_state = 71)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weights = [0.9999, 0.0001] <br>\n",
    "-> クラスの比率。例えば、[0.9, 0.1] と与えると0が90%、1が10%になる\n",
    "\n",
    "flip_y = 0 <br>\n",
    "-> クラスのフリップ率。例えば0.01とすると各クラスの1%の符号がランダムに変更される\n",
    "\n",
    "class_sep = 1.0, hypercube = True<br>\n",
    "-> 生成アルゴリズムに関係するパラメータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "df_raw = DataFrame(df[0], columns = ['var1', 'var2', 'var3', 'var4', 'var5', 'var6', 'var7', 'var8', 'var9', 'var10'])\n",
    "df_raw['Class'] = df[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "クラスの割合は、以下のようになっています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    99990\n",
       "1       10\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['Class'].value_counts()\n",
    "\n",
    "# 出力\n",
    "#0    99990\n",
    "#1       10\n",
    "#Name: Class, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ロジスティック回帰で分析してみる\n",
    "\n",
    "不均衡データをサンプリングしないまま、分類のためのロジスティック回帰モデルを作成してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# 学習用と検証用に分割\n",
    "X = df_raw.iloc[:, 0:10]\n",
    "y = df_raw['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 71)\n",
    "\n",
    "# モデル構築\n",
    "mod = LogisticRegression()\n",
    "mod.fit(X_train, y_train)\n",
    "\n",
    "# 予測値算出\n",
    "y_pred = mod.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正解率（Accuracy）は、以下になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy(test) : 0.99990\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy(test) : %.5f' %accuracy_score(y_test, y_pred))\n",
    "\n",
    "# 出力\n",
    "#Accuracy(test) : 0.99990"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このように、正解率99.99%という、一見精度が良さそうなモデルができています。\n",
    "\n",
    "しかし、混同行列を出力してみると"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29997, 0, 3, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "(tn, fp, fn, tp)\n",
    "\n",
    "# 出力\n",
    "#(29997, 0, 3, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出力結果から、<br>\n",
    "　TN（正でない（=0）ものを正でない（=0）と予測する）と<br>\n",
    "　FN（本当は正（=1）だが正でない（=0）と誤って予測する）<br>\n",
    "のみに値があり、<br>\n",
    "　　FP（本当は正でない（=0）ものを正である（=1）と誤って予測する）と<br>\n",
    "　　TP（正である（=1）ものを正である（=1）と予測する）<br>\n",
    "が0となっています。\n",
    "\n",
    "つまり、単にすべて0と予測するモデルになっています。\n",
    "\n",
    "Precision（正と予測したデータのうち，実際に正であるものの割合：TP / （TP + FP））と<br>\n",
    "Recall（実際に正であるもののうち，正であると予測されたものの割合：TP / （TP + FN））<br>\n",
    "\n",
    "を評価してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print('precision : %.4f'%(tp / (tp + fp)))\n",
    "\n",
    "# 出力\n",
    "#precision : nan\n",
    "#recall : 0.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall : 0.0000\n"
     ]
    }
   ],
   "source": [
    "print('recall : %.4f'%(tp / (tp + fn)))\n",
    "\n",
    "#recall : 0.0000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "計算が不能になっているか、0になっているという、ひどい結果です。\n",
    "\n",
    "実質意味のある予測ができるモデルではありません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Under Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "サンプル数　　　負：99990　正：10　のサンプル<br>\n",
    "ここでは、<b>負例を減らして</b>結果がどう変わるかを見てみます。\n",
    "\n",
    "imbalanced-learnで提供されているRandomUnderSamplerで、<br>\n",
    "負例サンプルをランダムに減らし、正例サンプルの割合を10%まで上げます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリ\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# 正例の数を保存\n",
    "positive_count_train = y_train.sum()\n",
    "# print('positive count:{}'.format(positive_count_train))とすると7件\n",
    "\n",
    "# 正例が10％になるまで負例をダウンサンプリング\n",
    "rus = RandomUnderSampler(ratio={0:positive_count_train*9, 1:positive_count_train}, random_state=71)\n",
    "\n",
    "# 学習用データに反映\n",
    "X_train_resampled, y_train_resampled = rus.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "あとはプロトタイプモデル作成の際と同様、ロジスティック回帰モデルを構築し、性能を見てみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix(test):\n",
      "[[29070   927]\n",
      " [    1     2]]\n",
      "Accuracy(test) : 0.96907\n"
     ]
    }
   ],
   "source": [
    "# モデル作成\n",
    "mod = LogisticRegression()\n",
    "mod.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 予測値算出\n",
    "y_pred = mod.predict(X_test)\n",
    "\n",
    "# Accuracyと混同行列\n",
    "print('Confusion matrix(test):\\n{}'.format(confusion_matrix(y_test, y_pred)))\n",
    "print('Accuracy(test) : %.5f' %accuracy_score(y_test, y_pred))\n",
    "\n",
    "# 出力\n",
    "#Accuracy(test) : 0.96907\n",
    "#Confusion matrix(test):\n",
    "#[[29070   927]\n",
    "# [    1     2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 0.0022\n",
      "recall : 0.6667\n"
     ]
    }
   ],
   "source": [
    "# PrecisionとRecall\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print('precision : %.4f'%(tp / (tp + fp)))\n",
    "print('recall : %.4f'%(tp / (tp + fn)))\n",
    "\n",
    "# 出力\n",
    "#precision : 0.0022\n",
    "#recall : 0.6667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正解率は落ちたものの、PrecisionとRecallが0でない値になりました。\n",
    "\n",
    "混同行列を見ても、TPが0でなくなっており、FNが小さくなっていることがわかります。<br>\n",
    "しかし、その代償としてFPが927件と大きくなってしまい、それが小さいPrecisionとして跳ね返っています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Over Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "サンプル数　　　負：99990　正：10　のサンプル<br>\n",
    "今度は逆に<b>正例を水増し</b>して正例サンプルの割合を10%まで上げます。\n",
    "\n",
    "imbalanced-learnで提供されているRandomOverSamplerで行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/imbalanced_learn-0.4.0.dev0-py3.6.egg/imblearn/utils/validation.py:230: UserWarning: After over-sampling, the number of samples (70000) in class 0 will be larger than the number of samples in the majority class (class #0 -> 69993)\n",
      "  n_samples_majority))\n"
     ]
    }
   ],
   "source": [
    "# ライブラリ\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# 正例を10％まであげる\n",
    "ros = RandomOverSampler(ratio = {0:X_train.shape[0], 1:X_train.shape[0]//9}, random_state = 71)\n",
    "\n",
    "# 学習用データに反映\n",
    "X_train_resampled, y_train_resampled = ros.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under Samplingの場合と同様、モデルを作成して性能を見てみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix(test):\n",
      "[[29693   304]\n",
      " [    1     2]]\n",
      "Accuracy(test) : 0.98983\n"
     ]
    }
   ],
   "source": [
    "# モデル作成\n",
    "mod = LogisticRegression()\n",
    "mod.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 予測値算出\n",
    "y_pred = mod.predict(X_test)\n",
    "\n",
    "# Accuracyと混同行列\n",
    "print('Confusion matrix(test):\\n{}'.format(confusion_matrix(y_test, y_pred)))\n",
    "print('Accuracy(test) : %.5f' %accuracy_score(y_test, y_pred))\n",
    "\n",
    "# 出力\n",
    "#Accuracy(test) : 0.98983\n",
    "#Confusion matrix(test):\n",
    "#[[29693   304]\n",
    "# [    1     2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 0.0065\n",
      "recall : 0.6667\n"
     ]
    }
   ],
   "source": [
    "# PrecisionとRecall\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print('precision : %.4f'%(tp / (tp + fp)))\n",
    "print('recall : %.4f'%(tp / (tp + fn)))\n",
    "\n",
    "# 出力\n",
    "#precision : 0.0065\n",
    "#recall : 0.6667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under Samplingの場合と比較して、FPの数が若干抑えられており（304件）、<br>\n",
    "Precisionが若干良くなっています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のOver Samplingでは、正例を単に水増ししていたのですが、<br>\n",
    "負例を減らし、正例を増やす、といった考えもあります。\n",
    "\n",
    "こういった方法の一つに、<b>SMOTE（Synthetic Minority Over-sampling Technique）</b><br>\n",
    "というアルゴリズムがあります。<br>\n",
    "imbalanced-learnでは、このSMOTEも提供されているので、ここでも試してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/imbalanced_learn-0.4.0.dev0-py3.6.egg/imblearn/utils/validation.py:230: UserWarning: After over-sampling, the number of samples (70000) in class 0 will be larger than the number of samples in the majority class (class #0 -> 69993)\n",
      "  n_samples_majority))\n"
     ]
    }
   ],
   "source": [
    "# ライブラリ\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# SMOTE\n",
    "smote = SMOTE(ratio={0:X_train.shape[0], 1:X_train.shape[0]//9}, random_state=71)\n",
    "X_train_resampled, y_train_resampled = smote.fit_sample(X_train, y_train)\n",
    "\n",
    "# モデル作成\n",
    "mod = LogisticRegression()\n",
    "mod.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 予測値算出\n",
    "y_pred = mod.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix(test):\n",
      "[[29675   322]\n",
      " [    1     2]]\n",
      "Accuracy(test) : 0.98923\n"
     ]
    }
   ],
   "source": [
    "# Accuracyと混同行列\n",
    "print('Confusion matrix(test):\\n{}'.format(confusion_matrix(y_test, y_pred)))\n",
    "print('Accuracy(test) : %.5f' %accuracy_score(y_test, y_pred))\n",
    "\n",
    "# 出力\n",
    "#Accuracy(test) : 0.98923\n",
    "#Confusion matrix(test):\n",
    "#[[29675   322]\n",
    "# [    1     2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 0.0062\n",
      "recall : 0.6667\n"
     ]
    }
   ],
   "source": [
    "# PrecisionとRecall\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print('precision : %.4f'%(tp / (tp + fp)))\n",
    "print('recall : %.4f'%(tp / (tp + fn)))\n",
    "\n",
    "# 出力\n",
    "#precision : 0.0062\n",
    "#recall : 0.6667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under/Over Samplingを両方合わせ技でやっているので、<br>\n",
    "Under SamplingとOver Samplingの間くらいの性能になりました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "・今回はOver Samplingが一番有効でありましたが、データが与えられたときに<br>\n",
    "　有力な手法はそのデータの性質に依存する部分も大きい。<br>\n",
    "\n",
    "・なのでどういったサンプリングがよいかは、都度色々試してみて決める必要あり。\n",
    "\n",
    "imbalanced-learnには、上記3つ以外にもサンプリングの方法が実装されています。<br>\n",
    "\n",
    "imbalanced-learn API — imbalanced-learn 0.3.0 documentation<br>\n",
    "http://contrib.scikit-learn.org/imbalanced-learn/stable/api.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考文献\n",
    "不均衡データに対するClassification<br>\n",
    "https://qiita.com/ryouta0506/items/619d9ac0d80f8c0aed92\n",
    "\n",
    "imbalanced-learnで不均衡なデータのunder-sampling/over-samplingを行う<br>\n",
    "http://ohke.hateblo.jp/entry/2017/08/18/230000\n",
    "\n",
    "不均衡データをdownsampling + baggingで補正すると汎化性能も確保できて良さそう<br>\n",
    "http://tjo.hatenablog.com/entry/2017/08/11/162057\n",
    "\n",
    "不均衡なデータの分類問題について with Python<br>\n",
    "http://kamonohashiperry.com/archives/469\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
